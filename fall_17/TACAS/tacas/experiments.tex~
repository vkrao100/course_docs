\section{Experiments and Discussions}
\label{sec:exp}

We have implemented Algorithm~\ref{algo:chainofinter}, including the 
procedures for the computation of $J_S$, $J_L$, $J_D$, and $SM(J_D)$,
using the {\scshape SINGULAR} symbolic algebra computation system
[ver. 4-1-0]\cite{DGPS_410}. The experiments were conducted on a
desktop computer with a 3.5GHz Intel $\text{Core}^{\text{TM}}$
i7-4770K Quad-core CPU, 16 GB RAM, running 64-bit Linux OS. The
results are presented in Table \ref{exp_algo1}.   

\par We experimented with a set of benchmarks that contain i) random
subset-sum problems ({\it subset-i}), ii) equivalence checking
instances between combinational finite field multiplier circuits
(Mastrovito vs. Montgomery) % (2$\times$2 and 3$\times$3 multipliers)
 \cite{lv:date2012}, and iii) equivalence checking instances between
 sequential finite field multiplier circuits (Sequential Multipliers
 with Parallel Outputs (SMPO) \cite{agnew1991implementation}).
%which is a Galois field normal basis modulo multiplier
%implementation, and a golden {\it spec} model.   
Some of the benchmarks are available 
as CNF formulas, which were converted to 
polynomials in $\F_2$,  whereas others were directly available as
polynomials in $\F_2$ (from \cite{xiaojun:cp2016}).

\par For the circuit benchmarks, the initial set of polynomial
constraints are partitioned into $J_A$ and $J_B$ such that the
primary input variables are common to both $J_A$ and $J_B$, while
keeping the generating sets of $J_A$ and $J_B$ as balanced as
possible. For the subset-sum problems, the generators of ideal $J$ are
randomly partitioned into generators for $J_A$ and $J_B$  such that $C
\neq \emptyset$.   
%Before starting any computation, we perform a check to make sure 
%that $GB(J_A)$ or $GB(J_B)$ is not 1.

\begin{table}[H]
\centering
\caption{Results of our experiment with the benchmarks. (*) denotes
that the benchmark was available as CNF formulas. T denotes 
time and is given in seconds.}
\label{exp_algo1}
\begin{tabular}{| c | c | c | c | c | c | c | c |} \hline
Benchmarks &\#Vars &($|J_A|$,$|J_B|$)& T($J_D$)& \#$SM(J_D)$&$|L|$ in Alg.~\ref{algo:chainofinter}&T(Alg.~\ref{algo:chainofinter}) & Total T\\ \hline \hline
subset-1            &(8,8,12)&(50,50)&12.7&4,008&3&0.8&15.2 \\ \hline
subset-2            &(14,3,16)&(70,71)&101.0&65,501&4&19.6&370.6 \\ \hline
subset-3            &(11,8,9)&(59,59)&0.2&505&4&0.1&0.4 \\ \hline
MasVMont 2$\times$2*&(3,3,5)&(13,14)&0.0&8&3&0.0&0.0 \\ \hline
MasVMont 3$\times$3&(35,39,13)&(42,42)&20.1&7,104&3&7.8&34.2 \\ \hline
SMPO 3$\times$3     &(18,20,10)&(22,23)&7,749.4&832&3&3.7&7,803.8 \\ \hline
SMPO 4$\times$4*    &(18,16,17)&(88,88)&1,106.7&122,816&3&27.7&2,281.6 \\ \hline
SMPO 5$\times$5*   &(24,25,17)&(120,120)&1.6&110,592&3&711.6& 1727\\ \hline
\end{tabular}
\end{table}

In Table \ref{exp_algo1}, \#Vars is 
a 3-tuple $(|A|,|B|,|C|)$ which denotes the sizes of the
variable partitions. The number of initial generators of
$J_A$ and $J_B$ are presented in column 3. Columns 4 
and 5 represent the time for computing (the GB of) $J_D$, and the
number of standard monomials of  $J_D$, respectively. In line 4 
in Algorithm \ref{algo:chainofinter}, we need to pick a polynomial $f_i$ of
the form $\sum_{i=1}^{i=l}\lambda_i\cdot m_i$. In our implementation,
we randomly create a polynomial $f_i = sm[ |sm|/2 ]+1$, where $sm$ is the list 
containing all $SM(J_D)$. % (we make sure that $sm[|sm|/2]\neq1$). 
In line 8 of Algorithm \ref{algo:chainofinter}, we need to find $g_j
\in G_{Di}$, which is again of the form
$\sum_{i=1}^{i=l}\lambda_i\cdot m_i$ and is not equal to the current $f_i$. 
We go through the polynomials in $G_{Di}$ and pick the first
polynomial satisfying these conditions. Columns 6 and 7 in Table
\ref{exp_algo1} denote the number of interpolants returned by 
our algorithm, and its execution time, respectively.
The last column denotes the total time taken by the implementation,
which is the aggregate of times required to compute $GB(J_s), GB(J_L), GB(J_D),
SM(J_D)$ and Algorithm \ref{algo:chainofinter}. 

\par The execution time for the benchmark MasVMont 2$\times$2 is
mentioned as $0.0$ because it is less than $50$ms. For most of the
benchmarks, a large part of the total time is consumed in computing $J_L$
and $J_D$, that involves the quotient of ideal operation. 
%The SMPO 5$\times$5 takes most of the time ($\sim$80\% of total time)
%to perform the initial check that $GB(J_A)\neq1$ or $GB(J_B)\neq1$. 
From the experiments, we notice that only a few interpolants (besides
$J_S$ and $J_L$) are generated by our algorithm. This depends on the
polynomials that we use in lines 4 and 8 of the Algorithm  
\ref{algo:chainofinter}. 
%We experimented with a few different polynomials for the line 4 for
%the subset-sum benchmarks but the number of interpolants remained approximately the same.
This implies that the algorithm makes huge ``jumps'' along the height
of interpolant lattice, which is equal 
to $l+1$ ($l=|SM(J_D)|$). We are currently investigating in more
detail the relationship between the standard monomial of $J_D$ and
$V_C(J_D)$ so that we can develop a better heuristic that provides
for a more guided exploration of the interpolant lattice. 

These experiments are made available to the reviewers from the
website:

\url{http://eng.utah.edu/\~utkarshg/tools.html}, where these design
benchmarks and the SINGULAR code is released.

% Fig. \ref{Fig:int_lat} denotes the interpolant lattice for the Example \ref{ex:main}. We get larger 
% interpolants as we traverse up the lattice. A connection between two vertices denotes 
% that the upper interpolant contains the lower interpolant. Interpolants at the same horizontal
% level are of the same size. The depth of this lattice is the total number of levels starting from 
% the bottom-most level $\Vc(J_S)$ (which in this example is 4), and the width is
% the total number of interpolants in each level (for the bottom-most level, width = 1; for the
% next higher level, width = 3).

%% \par \noindent \underline{Discussions:} 
%% \begin{itemize}
%% \item The theorems and algorithm presented 
%% in the sections \ref{sec:theory} and \ref{sec:alg} make use of Gr\"obner basis concepts
%% and rely on GB computation. The computational complexity of
%% Buchberger's algorithm is exponential making these theorems practically infeasible. 
%% \par GB concepts are being extensively used in the verification of hardware circuits. 
%% When operating over Boolean circuits, \cite{pruss:tcad} and \cite{xiaojun:hldvt2016}
%% describe a topological monomial order that can be 
%% derived from the gates of the circuit. This order obviates the need to explicitly compute a 
%% Gr\"obner basis and the overall complexity is dictated by polynomial reductions. 
%% \par We are currently working on orderings and heuristics that can avoid GB computation complexity
%% when the Craig interpolants are used for circuit based applications like logic synthesis.
%% However, before these techniques can be applied to circuits, a theory of
%% Craig interpolants in finite fields needs to be set in place which 
%% is the primary purpose of this paper.

%% \item As an improvement to our approach, the step in line 13 of Algorithm~\ref{algo:chainofinter} can use improved heuristic 
%% when choosing a $g_j$. Instead of selecting just one $g_j$ of the form $\sum_{i=1}^{i=l} \lambda_i \cdot m_i$,
%% one can also select a linear combination of multiple $g_j$ as long as this combination does not
%% compute to $f_i$. This is because the combination of multiple $g_j$ is still of the
%% form $\sum_{i=1}^{i=l} \lambda_i \cdot m_i$. 
%% \par From Example \ref{ex:main} we know that $\Vc(J_1) \subset \Vc(J_5)$
%% and $\Vc(J_1) \subset \Vc(J_6)$. We also saw in the Example \ref{ex:chainofinter} that we can
%% obtain $J_5$ by selecting $g_1 = b+1$ from the set $GB(J_D + \langle f_1 \rangle)$. If we consider the linear 
%% combination $g_3$ of $g_1$ and $g_2$ obtained as $g_3 = g_1 + g_2 = b+c+1$, then from Example \ref{ex:enuall},
%% $g_3 = f_6$ and can be used to compute $J_6$. 

%% \end{itemize} 
